{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from transformers import Transformer\n",
    "from transformer_train import Batch, NoamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(input_vocab=10, output_vocab=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using the transformer with None mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.2956, -5.5360, -3.9026,  ..., -2.2101, -5.1254, -2.0607],\n",
       "         [-3.1119, -4.2495, -3.3671,  ..., -1.4571, -4.2381, -1.4444],\n",
       "         [-2.7520, -3.7801, -2.3611,  ..., -1.6817, -3.7349, -3.0017],\n",
       "         ...,\n",
       "         [-2.6767, -3.8117, -2.3582,  ..., -1.7804, -3.6750, -2.8720],\n",
       "         [-3.1573, -5.9229, -3.5439,  ..., -2.5666, -5.2111, -1.9874],\n",
       "         [-1.8012, -4.4187, -3.2388,  ..., -2.3578, -3.4859, -1.8860]],\n",
       "\n",
       "        [[-2.7531, -5.1500, -5.0741,  ..., -0.4916, -4.0239, -3.6269],\n",
       "         [-3.2632, -2.8007, -2.6924,  ..., -0.7778, -3.2491, -5.0723],\n",
       "         [-3.8677, -3.5181, -4.3830,  ..., -0.3828, -3.6132, -3.7635],\n",
       "         ...,\n",
       "         [-2.7543, -5.2842, -5.1500,  ..., -0.4658, -4.0015, -3.6083],\n",
       "         [-1.6570, -3.0861, -4.0031,  ..., -1.3562, -2.7431, -3.8556],\n",
       "         [-3.4830, -3.4247, -4.2928,  ..., -0.4624, -3.7082, -3.6337]],\n",
       "\n",
       "        [[-3.1270, -3.5810, -1.9032,  ..., -2.7086, -3.3358, -2.8965],\n",
       "         [-3.3003, -4.0092, -2.2468,  ..., -2.9623, -3.8744, -2.7411],\n",
       "         [-3.3074, -3.6185, -1.4718,  ..., -1.9450, -2.8191, -3.5201],\n",
       "         ...,\n",
       "         [-4.0968, -3.7806, -2.4140,  ..., -2.6286, -3.5468, -2.2286],\n",
       "         [-3.9957, -4.7974, -3.4315,  ..., -4.1130, -4.1429, -3.4428],\n",
       "         [-2.3298, -5.4576, -3.5539,  ..., -2.5078, -3.8911, -2.8147]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.7914, -2.5710, -3.1047,  ..., -1.7886, -2.3712, -2.0903],\n",
       "         [-3.5836, -3.5542, -3.2119,  ..., -1.6882, -3.7943, -2.0931],\n",
       "         [-3.3777, -3.1038, -2.7285,  ..., -1.1234, -3.0624, -2.5106],\n",
       "         ...,\n",
       "         [-2.6361, -2.8206, -2.8471,  ..., -1.6634, -2.2620, -2.0607],\n",
       "         [-4.2350, -4.5370, -4.0620,  ..., -2.2668, -3.6534, -2.1590],\n",
       "         [-3.4898, -3.6912, -2.9358,  ..., -1.7451, -3.6516, -1.9606]],\n",
       "\n",
       "        [[-3.0945, -6.1279, -5.2297,  ..., -1.2950, -4.1704, -3.6873],\n",
       "         [-3.2140, -6.2533, -5.3637,  ..., -1.2374, -4.2982, -3.7575],\n",
       "         [-4.3526, -4.9207, -3.7710,  ..., -1.2854, -3.9047, -3.8614],\n",
       "         ...,\n",
       "         [-4.2945, -4.8176, -3.4545,  ..., -0.8363, -2.7944, -4.3519],\n",
       "         [-3.6516, -3.6307, -2.7753,  ..., -1.1517, -3.2484, -4.5432],\n",
       "         [-3.6193, -4.1981, -3.4193,  ..., -1.1720, -3.0663, -3.8479]],\n",
       "\n",
       "        [[-3.8952, -3.2656, -2.8696,  ..., -1.2856, -3.1391, -2.0587],\n",
       "         [-5.1046, -4.2155, -3.0382,  ..., -1.6012, -3.9427, -2.6322],\n",
       "         [-3.3791, -6.1494, -4.6574,  ..., -1.7938, -4.3888, -2.7832],\n",
       "         ...,\n",
       "         [-3.6221, -3.8039, -2.3891,  ..., -1.5503, -3.2003, -2.3705],\n",
       "         [-4.2057, -4.6009, -3.1085,  ..., -2.0824, -3.7946, -2.2824],\n",
       "         [-4.8306, -5.4527, -4.6725,  ..., -2.9751, -4.5020, -3.0426]]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randint(10, (60,5))\n",
    "output = torch.randint(10, (60,10))\n",
    "transformer(input, output, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using the transformer with real mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.0528, -5.5559, -2.0790,  ..., -1.0352, -3.4822, -2.6008],\n",
       "         [-3.6055, -3.3336, -2.2586,  ..., -1.6918, -2.0672, -2.6547],\n",
       "         [-4.8799, -5.0606, -2.4573,  ..., -1.5500, -2.7496, -1.9709],\n",
       "         ...,\n",
       "         [-3.9195, -5.5816, -3.4783,  ..., -2.5231, -3.1341, -2.3260],\n",
       "         [-3.4349, -3.6073, -2.1571,  ..., -1.9795, -1.9738, -2.4010],\n",
       "         [-2.6095, -4.9476, -2.3122,  ..., -1.3448, -2.9295, -2.5103]],\n",
       "\n",
       "        [[-3.4173, -3.0684, -3.9996,  ..., -5.5370, -4.3073, -5.7417],\n",
       "         [-2.2009, -1.6852, -1.7232,  ..., -3.5195, -3.5730, -3.3904],\n",
       "         [-1.7419, -1.3112, -2.9169,  ..., -4.5100, -2.8470, -4.4936],\n",
       "         ...,\n",
       "         [-2.5086, -4.1357, -2.4378,  ..., -3.4512, -4.6265, -3.9577],\n",
       "         [-2.5960, -1.7321, -2.2847,  ..., -3.4647, -3.4665, -3.7475],\n",
       "         [-1.4079, -2.1173, -2.5516,  ..., -4.4490, -3.2443, -4.1437]],\n",
       "\n",
       "        [[-3.4947, -2.8191, -3.0925,  ..., -0.6011, -2.7757, -4.1271],\n",
       "         [-4.6926, -5.4174, -4.1692,  ..., -0.3756, -2.7553, -3.9577],\n",
       "         [-3.8280, -6.3807, -5.1750,  ..., -0.4143, -4.7192, -3.1192],\n",
       "         ...,\n",
       "         [-3.5706, -4.6303, -3.7246,  ..., -0.4243, -3.2065, -3.5638],\n",
       "         [-2.6852, -5.3485, -5.2030,  ..., -0.7454, -3.6629, -2.8463],\n",
       "         [-2.5824, -3.8106, -3.9686,  ..., -1.0770, -2.4398, -2.7334]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.7052, -2.8142, -3.4454,  ..., -2.5283, -4.3312, -3.4274],\n",
       "         [-4.1949, -0.8044, -2.9412,  ..., -2.1774, -3.5474, -3.4890],\n",
       "         [-3.2251, -1.1017, -1.7459,  ..., -1.7876, -3.8947, -4.9488],\n",
       "         ...,\n",
       "         [-2.6838, -1.8433, -1.9658,  ..., -1.0937, -3.4669, -3.5240],\n",
       "         [-2.3465, -2.0687, -2.6583,  ..., -2.2797, -4.3861, -3.2444],\n",
       "         [-3.2682, -1.5266, -2.6888,  ..., -1.5399, -3.2130, -3.4308]],\n",
       "\n",
       "        [[-3.6550, -4.2561, -2.3498,  ..., -1.4612, -1.9030, -4.3679],\n",
       "         [-4.0950, -3.8854, -2.7008,  ..., -2.6176, -2.8468, -3.3455],\n",
       "         [-4.0289, -4.3977, -2.7782,  ..., -2.4195, -3.1373, -3.6072],\n",
       "         ...,\n",
       "         [-3.3967, -4.4247, -2.3401,  ..., -1.7436, -2.9950, -3.1283],\n",
       "         [-4.0498, -5.1112, -3.9292,  ..., -3.7651, -2.7601, -3.9308],\n",
       "         [-3.5047, -3.3727, -2.0614,  ..., -1.6999, -2.5789, -2.8839]],\n",
       "\n",
       "        [[-2.0750, -3.8167, -1.7726,  ..., -3.3329, -3.2577, -2.6248],\n",
       "         [-3.8044, -4.6471, -2.8744,  ..., -3.8526, -4.4542, -2.6140],\n",
       "         [-3.3723, -4.3012, -1.8839,  ..., -3.7241, -4.5078, -3.0917],\n",
       "         ...,\n",
       "         [-2.9451, -3.7427, -1.1425,  ..., -2.2682, -3.6043, -3.5502],\n",
       "         [-3.6089, -3.9922, -1.7788,  ..., -3.2018, -2.7808, -2.8833],\n",
       "         [-2.8311, -4.2912, -2.2936,  ..., -3.9416, -3.7286, -2.0193]]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randint(10, (60,5))\n",
    "output = torch.randint(10, (60,10))\n",
    "input_mask = torch.randint(2, (60, 1, 5))\n",
    "output_mask = torch.randint(2, (60, 10, 10))\n",
    "transformer(input, output, input_mask, output_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and training transformer for copy task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vocab = 11\n",
    "seq_len = 10\n",
    "model_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data_generator(num_batches=30, batch_size=20):\n",
    "    for _ in range(num_batches):\n",
    "        data = np.random.randint(num_vocab, size=(batch_size, seq_len))\n",
    "        src = torch.from_numpy(data)\n",
    "        tgt = torch.from_numpy(data.copy())\n",
    "        yield Batch(src, tgt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(input_vocab=num_vocab, output_vocab=num_vocab, model_dim=model_dim, num_coder=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = torch.optim.Adam(transformer.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)\n",
    "noam_optimizer = NoamOptimizer(adam_optimizer, model_dim, 1, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.302064045270284\n",
      "1 1.8219502607981364\n",
      "2 1.7427995483080545\n",
      "3 1.2776670634746552\n",
      "4 0.9659743865331014\n",
      "5 0.8486938496430715\n",
      "6 0.7245328962802887\n",
      "7 0.7513565500577291\n",
      "8 0.7873012860616048\n",
      "9 0.8102462132771809\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0, label_smoothing=0.1)\n",
    "\n",
    "for epoch in range(10):\n",
    "    transformer.train()\n",
    "    data_iter = copy_data_generator()\n",
    "\n",
    "    losses = 0.\n",
    "    cnt = 0\n",
    "\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out = transformer(batch.src, batch.trg, batch.src_mask, batch.trg_mask)\n",
    "\n",
    "        out = out.reshape(-1, out.shape[-1])\n",
    "        labels = batch.trg_y.reshape(-1)\n",
    "\n",
    "        loss = loss_fn(out, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        noam_optimizer.step()\n",
    "        noam_optimizer.optimizer.zero_grad()\n",
    "\n",
    "        losses += loss.item()\n",
    "        cnt += 1\n",
    "\n",
    "    print(epoch, losses / cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing transformer for copy task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.random.randint(num_vocab, size=(10, seq_len))\n",
    "\n",
    "expected_output = torch.from_numpy(input.copy()) \n",
    "output_init = torch.from_numpy(input[:,0].reshape(-1,1))\n",
    "input = torch.from_numpy(input)\n",
    "input_mask = torch.ones(10, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = transformer.greedy_decode(input, output_init, seq_len, input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  2,  9,  0,  4, 10,  5,  9,  5,  6],\n",
       "        [ 4,  0,  1,  8,  2,  3, 10,  4, 10, 10],\n",
       "        [ 9,  6,  7,  8,  9,  5, 10, 10,  3,  9],\n",
       "        [ 1,  4,  8,  4,  9,  3,  9, 10,  5,  8],\n",
       "        [ 5,  5,  6,  3,  8,  8,  3,  8,  9,  6],\n",
       "        [ 2,  9,  8,  1,  9,  1,  4,  0, 10,  4],\n",
       "        [ 1,  4,  5,  4,  8,  4,  0,  9,  6,  2],\n",
       "        [ 1,  6,  9,  9,  3,  8,  6,  2,  7,  5],\n",
       "        [ 8,  4,  0,  2, 10,  8,  2,  7,  8,  3],\n",
       "        [ 3,  7,  4,  9,  7,  3,  0,  9,  8,  4]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  2,  9,  3,  4, 10,  5,  9,  5,  9],\n",
       "        [ 4,  1,  1,  8,  3,  3, 10, 10,  4, 10],\n",
       "        [ 9,  7,  7,  8,  9,  5, 10, 10, 10,  9],\n",
       "        [ 1,  4,  8,  4,  9,  3,  9, 10,  9,  8],\n",
       "        [ 5, 10,  6,  3,  8,  3,  3,  8,  9,  6],\n",
       "        [ 2,  9,  8,  1,  1,  1,  4, 10, 10, 10],\n",
       "        [ 1,  4,  5,  4,  8,  4,  3,  9,  6,  2],\n",
       "        [ 1,  6,  9,  9,  3,  8,  6,  2,  7,  5],\n",
       "        [ 8,  4,  3,  2, 10,  8,  2,  7,  8,  8],\n",
       "        [ 3,  7,  4,  9,  7,  3,  4,  9,  8,  8]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8100000023841858"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy \n",
    "acc = (output == expected_output).sum() / (10 * seq_len)\n",
    "acc.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and training transformer for sequence reversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vocab = 11\n",
    "seq_len = 10\n",
    "model_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_data_generator(num_batches=30, batch_size=20):\n",
    "    for _ in range(num_batches):\n",
    "        data = np.random.randint(num_vocab, size=(batch_size, seq_len))\n",
    "        src = torch.from_numpy(data)\n",
    "        tgt = torch.from_numpy(data[:, ::-1].copy())\n",
    "        yield Batch(src, tgt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(input_vocab=num_vocab, output_vocab=num_vocab, model_dim=model_dim, num_coder=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = torch.optim.Adam(transformer.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)\n",
    "noam_optimizer = NoamOptimizer(adam_optimizer, model_dim, 1, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.27563191652298\n",
      "1 1.8106411576271058\n",
      "2 1.6703855593999226\n",
      "3 1.313740042845408\n",
      "4 0.948525055249532\n",
      "5 0.8531302829583486\n",
      "6 0.8086230039596558\n",
      "7 0.6997813681761423\n",
      "8 0.7196457803249359\n",
      "9 0.7307352046171824\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0, label_smoothing=0.1)\n",
    "\n",
    "for epoch in range(10):\n",
    "    transformer.train()\n",
    "    data_iter = reverse_data_generator()\n",
    "\n",
    "    losses = 0.\n",
    "    cnt = 0\n",
    "\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out = transformer(batch.src, batch.trg, batch.src_mask, batch.trg_mask)\n",
    "\n",
    "        out = out.reshape(-1, out.shape[-1])\n",
    "        labels = batch.trg_y.reshape(-1)\n",
    "\n",
    "        loss = loss_fn(out, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        noam_optimizer.step()\n",
    "        noam_optimizer.optimizer.zero_grad()\n",
    "\n",
    "        losses += loss.item()\n",
    "        cnt += 1\n",
    "\n",
    "    print(epoch, losses / cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing transformer for sequence reversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.random.randint(num_vocab, size=(10, seq_len))\n",
    "\n",
    "expected_output = torch.from_numpy(input[:, ::-1].copy()) \n",
    "output_init = torch.from_numpy(input[:,-1].reshape(-1,1))\n",
    "input = torch.from_numpy(input)\n",
    "input_mask = torch.ones(10, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = transformer.greedy_decode(input, output_init, seq_len, input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  7,  7,  5,  8,  6,  4,  2,  1,  5],\n",
       "        [ 4,  3,  5,  7,  8,  1,  8,  8,  9, 10],\n",
       "        [ 8,  9,  9,  9,  8,  1,  9,  2,  6,  0],\n",
       "        [10,  2,  9,  2,  8,  5,  5,  3,  5,  0],\n",
       "        [ 6,  4,  4,  6,  5,  9,  9,  8,  6,  3],\n",
       "        [ 0,  7,  2,  7,  9,  9,  7,  0,  9,  0],\n",
       "        [ 4,  6,  7,  7,  8,  4,  7,  1,  3,  5],\n",
       "        [ 6,  2,  5, 10,  4,  9,  5, 10,  4,  0],\n",
       "        [ 8,  9, 10,  7,  9,  7,  4,  0,  9, 10],\n",
       "        [ 9,  2,  0,  0,  9,  7,  0,  3,  2,  6]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  7,  5,  7,  8,  6,  4,  2,  1,  5],\n",
       "        [ 4,  3,  5,  7,  8,  1,  8,  9, 10, 10],\n",
       "        [ 8,  9,  9,  9,  8,  1,  9,  2,  6,  1],\n",
       "        [10,  2,  9,  2,  8,  5,  5,  3,  5,  9],\n",
       "        [ 6,  4,  6,  5,  6,  9,  9,  8,  6,  3],\n",
       "        [ 0,  9,  7,  2,  9,  9,  7,  9,  9,  9],\n",
       "        [ 4,  6,  7,  7,  8,  4,  7,  1,  3,  5],\n",
       "        [ 6,  2,  5, 10,  4,  9,  5, 10,  4,  1],\n",
       "        [ 8,  9, 10,  7,  9,  7,  4,  9, 10,  9],\n",
       "        [ 9,  2,  9,  9,  7,  9,  7,  3,  2,  6]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7699999809265137"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy \n",
    "acc = (output == expected_output).sum() / (10 * seq_len)\n",
    "acc.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and training transformer for sequence sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vocab = 11\n",
    "seq_len = 5\n",
    "model_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_data_generator(num_batches=30, batch_size=20):\n",
    "    for _ in range(num_batches):\n",
    "        data = np.random.randint(num_vocab, size=(batch_size, seq_len))\n",
    "        src = torch.from_numpy(data)\n",
    "        tgt = torch.from_numpy(np.sort(data))\n",
    "        yield Batch(src, tgt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(input_vocab=num_vocab, output_vocab=num_vocab, model_dim=model_dim, num_coder=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = torch.optim.Adam(transformer.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)\n",
    "noam_optimizer = NoamOptimizer(adam_optimizer, model_dim, 1, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.6308037598927816\n",
      "1 0.9159865935643514\n",
      "2 0.8626769820849101\n",
      "3 0.8391406059265136\n",
      "4 0.8934044241905212\n",
      "5 0.8539911985397339\n",
      "6 0.9117301285266877\n",
      "7 0.919150443871816\n",
      "8 0.9773162444432576\n",
      "9 0.9681901276111603\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0, label_smoothing=0.1)\n",
    "\n",
    "for epoch in range(10):\n",
    "    transformer.train()\n",
    "    data_iter = sort_data_generator()\n",
    "\n",
    "    losses = 0.\n",
    "    cnt = 0\n",
    "\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out = transformer(batch.src, batch.trg, batch.src_mask, batch.trg_mask)\n",
    "\n",
    "        out = out.reshape(-1, out.shape[-1])\n",
    "        labels = batch.trg_y.reshape(-1)\n",
    "\n",
    "        loss = loss_fn(out, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        noam_optimizer.step()\n",
    "        noam_optimizer.optimizer.zero_grad()\n",
    "\n",
    "        losses += loss.item()\n",
    "        cnt += 1\n",
    "\n",
    "    print(epoch, losses / cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing transformer for sequence sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.random.randint(num_vocab, size=(10, seq_len))\n",
    "\n",
    "expected_output = torch.from_numpy(np.sort(input))\n",
    "output_init = torch.from_numpy(np.sort(input)[:,0].reshape(-1,1))\n",
    "input = torch.from_numpy(input)\n",
    "input_mask = torch.ones(10, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = transformer.greedy_decode(input, output_init, seq_len, input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  2,  6,  6,  8],\n",
       "        [ 3,  3,  6,  6,  7],\n",
       "        [ 3,  4,  5,  7, 10],\n",
       "        [ 3,  4,  4, 10, 10],\n",
       "        [ 0,  0,  4,  6,  8],\n",
       "        [ 0,  0,  5, 10, 10],\n",
       "        [ 3,  4,  6,  9, 10],\n",
       "        [ 1,  2,  3,  6,  8],\n",
       "        [ 1,  6,  7,  9, 10],\n",
       "        [ 0,  2,  2,  5,  5]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  2,  4,  6,  8],\n",
       "        [ 3,  3,  3,  6,  7],\n",
       "        [ 3,  4,  5,  7, 10],\n",
       "        [ 3,  4,  4,  4, 10],\n",
       "        [ 0,  1,  4,  6,  8],\n",
       "        [ 0,  5,  5,  5, 10],\n",
       "        [ 3,  4,  4,  4,  9],\n",
       "        [ 1,  2,  3,  6,  8],\n",
       "        [ 1,  7,  9, 10, 10],\n",
       "        [ 0,  2,  5,  5,  5]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7400000095367432"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy \n",
    "acc = (output == expected_output).sum() / (10 * seq_len)\n",
    "acc.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
